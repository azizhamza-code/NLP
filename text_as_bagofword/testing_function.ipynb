{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Hamza\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils import import_data\n",
    "from prepro import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filec:\\Users\\Hamza\\Documents\\project\\NLP\\data\\train.tsv is already download\n",
      "Filec:\\Users\\Hamza\\Documents\\project\\NLP\\data\\validation.tsv is already download\n",
      "Filec:\\Users\\Hamza\\Documents\\project\\NLP\\data\\test.tsv is already download\n",
      "Filec:\\Users\\Hamza\\Documents\\project\\NLP\\data\\text_prepare_tests.tsv is already download\n",
      "Filec:\\Users\\Hamza\\Documents\\project\\NLP\\data\\encoding.json is already download\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train , val ,test, encoder_instance = import_data(encoders_data=True)\n",
    "data_class = data(train ,val ,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:19:50.19 >>> Call to data.clean_and_encode_data in File \"c:\\Users\\Hamza\\Documents\\project\\NLP\\text_as_bagofword\\prepro.py\", line 137\n",
      "11:19:50.19 .......... self = <prepro.data object at 0x000001B02B38BD00>\n",
      "11:19:50.19 .......... encoder = <prepro.encode_label object at 0x000001B034C695A0>\n",
      "11:19:50.19 .......... len(encoder) = 100\n",
      "11:19:50.19  137 |     def clean_and_encode_data(self, encoder):\n",
      "11:19:50.19  139 |         self.train = data.clean_datafram(self.train)\n",
      "11:20:15.86  140 |         self.val = data.clean_datafram(self.val)\n",
      "11:20:27.60  141 |         self.test = data.clean_datafram(self.test, test=True)\n",
      "11:20:39.66  143 |         self.train = data.encode_datafram_label(encoder, self.train)\n",
      "11:20:39.98  144 |         self.val = data.encode_datafram_label(encoder, self.val)\n",
      "11:20:40.05  146 |         self.x_train, self.y_train = self.train.iloc[:,0].values, np.stack(self.train.iloc[:, 1].values)\n",
      "11:20:40.13  147 |         self.x_val, self.y_val = self.val.iloc[:,0].values, np.stack(self.val.iloc[:, 1].values)\n",
      "11:20:40.17  148 |         self.x_test = self.test.iloc[:,0].values\n",
      "11:20:40.17 <<< Return value from data.clean_and_encode_data: None\n"
     ]
    }
   ],
   "source": [
    "data_class.clean_and_encode_data(encoder=encoder_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class.y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import random_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model = random_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_model.fit(data_class.x_train , data_class.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = random_model.transform(data_class.x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class.y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of model failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Hamza\\Documents\\project\\NLP\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"c:\\Users\\Hamza\\Documents\\project\\NLP\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2032.0_x64__qbz5n2kfra8p0\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\Hamza\\Documents\\project\\NLP\\text_as_bagofword\\model.py\", line 3, in <module>\n",
      "    from sklearn.metrics import precision_recall_fscore_support\n",
      "ModuleNotFoundError: No module named 'sklearn'\n",
      "]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'metric' from 'model' (c:\\Users\\Hamza\\Documents\\project\\NLP\\text_as_bagofword\\model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metric\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'metric' from 'model' (c:\\Users\\Hamza\\Documents\\project\\NLP\\text_as_bagofword\\model.py)"
     ]
    }
   ],
   "source": [
    "from model import metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ad64e2f76d4b663e27dc016b301ff2b90262b1c123047d66778f2c46f1cc0cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
